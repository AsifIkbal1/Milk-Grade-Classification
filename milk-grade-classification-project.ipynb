{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Milk Grade Classification","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Coded by Luna McBride","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #plotting\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (15,10) #Set the default figure size\nplt.style.use('ggplot') #Set the plotting method\n\nfrom sklearn.model_selection import train_test_split #Split the data into train and test\nfrom sklearn.ensemble import RandomForestClassifier #Forest for prediction and regression\nfrom sklearn.metrics import mean_squared_error #Error testing\nfrom sklearn.metrics import classification_report #Report of Classification\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"milk = pd.read_csv(\"../input/milk-grading/Milk Grading (1).csv\") #Get the milk dataset\nmilk.head() #Take a peek at the milk","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Check for Null Values","metadata":{}},{"cell_type":"code","source":"print(milk.isnull().any()) #Check for null values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no null values.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Add a Column Putting Grade into Words","metadata":{}},{"cell_type":"code","source":"milk[\"gradeWord\"] = milk[\"Grade\"].apply(lambda x: \"Good\" if x==1 else (\"Moderate\" if x==0.5 else \"Bad\") ) #Put the grade into words\nmilk.head() #Take a peek at the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Basic Exploration","metadata":{}},{"cell_type":"markdown","source":"## Number of Rows","metadata":{}},{"cell_type":"code","source":"print(len(milk.index)) #Check the number of rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only 1059 entries.","metadata":{}},{"cell_type":"markdown","source":"## Count of Grades","metadata":{}},{"cell_type":"code","source":"milk[\"Grade\"].value_counts().plot.bar(title = \"Milk in Each Grade\") #Plot the number of instances of each grade","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It appears there are more grade 0 and 0.5 milks than 1.0, but not by too much.","metadata":{}},{"cell_type":"markdown","source":"## Range of Temperature/PH Values","metadata":{}},{"cell_type":"code","source":"rangeValues = [\"Temprature\", \"pH\", \"Colour\"] #Get the columns that are ranged values\n\n#For each ranged value column, print the range of the column (min and max)\nfor column in rangeValues:\n    #Print the range for these columns that have ranges\n    print(column, \"Range: \", milk[column].unique().min(), \"-\", milk[column].unique().max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gradeType = [\"Good\", \"Moderate\", \"Bad\"] #Get the word names for the different grades\n\n#For each grade, get the subset of the dataset for that grade and get its pH/Temp ranges\nfor grade in gradeType:\n    subset = milk.loc[milk[\"gradeWord\"] == grade] #Get the subset of the data for the specific grade\n    \n    #For each ranged value column, print the range of the column (min and max) per each grade\n    for column in rangeValues:\n        #Print the range for these columns that have ranges\n        print(grade, column, \"Range: \", subset[column].unique().min(), \"-\", subset[column].unique().max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The general ranges for the whole dataset appear to be 34-90, 3-9.5, and 240-255 for temperature, pH, and colour respectively. This also appears to be the total range for bad milks in the case of temperature and pH, where both moderate and good are more restrictive in those departments yet similar to one another. This tells be there are different criteria to deciding good/moderate vs bad and good vs moderate, so those may need to have different classification models to determine the characteristics.\n\nAs for colour, it seems to only come into play with moderate milks. This means it could be a factor in the difference between moderate and good, but we will have to see.","metadata":{}},{"cell_type":"markdown","source":"## Plot Each Column","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,4) #Update the graph sizes\n\n#For each milk column, plot it in a bar graph\nfor column in milk.columns:\n    plt.figure() #Get the figure so it will let me plot multiple\n    milk[column].value_counts().plot.bar(title = column) #Plot the specified column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The undiscussed columns appear to all be boolean in nature, with similar distributions of those to boot. The other variables, especially the ranged variables from earlier, have higher concentrations of values in the range used for good/moderate milk overall. ","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Classify the Whole Dataset","metadata":{}},{"cell_type":"code","source":"#GetChara: Get the most important characteristics to the classification\n#Input: the characteristics, the model\n#Output: None\ndef getChara(characteristics, forest):\n    attributes = characteristics.columns #Get the tested attributes\n    attributes = list(zip(attributes, forest.feature_importances_)) #Zip the attributes together with their coefficient\n    sortAtt = sorted(attributes, key = lambda x: x[1], reverse = True) #Sort the zipped attributes by their coefficients\n\n    print(\"According to the Random Forest, the most important factors for milk grade are: \") #Start printing the most important labels\n    i = 0 #Counter variable so only the top five are printed\n\n    #For each attribute in the sorted attributes\n    for label, coef in sortAtt:\n        if i < 7: #If there has not been five printed yet\n            print(label) #Print the label as an important factor\n        i += 1 #Increase i by 1\n\n#ClassifyMilk: Classify milk grade based on the labels\n#Input: The dataframe for the milk, the labels used\n#Output: None\ndef classifyMilk(milk, labels):\n    grade = milk[\"gradeWord\"].copy() #Get the grades as our classification metric\n    grade = pd.get_dummies(grade) #Get dummies for the grade metric\n    print(grade)\n\n    characteristics = milk.drop(columns = {\"Grade\", \"gradeWord\"}).copy() #Get the characteristics used for classification\n    charaTrain, charaTest, gradeTrain, gradeTest = train_test_split(characteristics, grade, test_size = 0.2) #Split the dataset\n    \n    forest = RandomForestClassifier(n_estimators = 100) #Build a forest\n    forest.fit(charaTrain, gradeTrain) #Fit the forest model\n    \n    predict = forest.predict(charaTest) #Get a list of predictions\n    \n    print(\"Forest Accuracy: \", forest.score(charaTest, gradeTest)) #Print the accuracy\n    print(\"Root Mean Square Error: \", np.sqrt(mean_squared_error(gradeTest, predict))) #Print the root mean square error\n    print(\"Classification Report:\\n \", classification_report(gradeTest, predict, target_names = labels)) #Print a classification report\n    \n    getChara(characteristics, forest) #Get the important Characteristics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grade = [\"Bad\", \"Good\", \"Moderate\"] #Get the grades in order\nclassifyMilk(milk, grade) #Classify on the whole dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the overall dataset (showing good/moderate versus bad), pH and Temperature come out on top as expected by looking at their ranges. Next comes Turbidity, Odor, and Fat, or rather it is considered worse if it is too foggy, too stinky, or had not enough fat.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Classify only Moderate and Good","metadata":{}},{"cell_type":"code","source":"grades = [\"Good\", \"Moderate\"] #Get the grades for this classification\nmilkLite = milk.loc[milk[\"gradeWord\"] != \"Bad\"] #Get all milks that are not bad\n\nclassifyMilk(milkLite, grades) #Classify every milk but bad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"pH and Temperature appeared to have more of a play when looking at bad milk rather than moderate vs good, but they do appear to still be relatively important. Fat and Odor took over when calling between moderate and good, telling me that these are the factors to distinguish between moderate and good milks.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"Overall, a random forest classifier could classify the milk grades at 99+% accuracy. The pH, Temperature, and Turbidity factors had the most at play when distinguishing bad milk, while Fat and Odor were the deciding calls between moderate and good milk. This, of course, is given the wide range of temperatures and pH's in the bad milk that are picked out before even being considered to the moderate/good categories.","metadata":{}}]}